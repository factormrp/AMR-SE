# Analysing Mathematical Reasoning -> Student Edition
This mini-project is an attempt at grasping the concept of a transformer. In particular, we used the [mathematics_dataset](https://github.com/deepmind/mathematics_dataset) released by Google DeepMind as part of their ICLR 2019 paper Analysing Mathematical Reasoning Abilities of Neural Models. We attempt to validate the results found therein by leveraging the [transformer model](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) proposed by Pytorch.

## Inspiration
The main reason we took on this was because we had been discussing the idea of creating a model that could process and understand mathematical text prompts and stumbled upon the DeepMind work. Further digging showed us that we were about a year late in our thinking but the idea was still fresh to us. Then we found a [Stanford students'](http://cs230.stanford.edu/projects_fall_2019/reports/26258425.pdf) final report paper on their validation attempt. Feeling confident this would be a great way to step into the pool, we took up the mantle ourselves.

